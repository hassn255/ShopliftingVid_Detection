{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305b6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e073192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "output_path = \"out_detect.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f2a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"shop_lifter_0.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"cannot open the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c2ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f64ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_person_from_video(\n",
    "    model,\n",
    "    input_path, \n",
    "    output_path, \n",
    "    expand_ratio=0.3, \n",
    "    output_size=(256, 256)\n",
    "):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    out = cv2.VideoWriter(\n",
    "        output_path, \n",
    "        cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "        fps, \n",
    "        output_size\n",
    "    )\n",
    "\n",
    "    boxes = []\n",
    "    frames = []\n",
    "\n",
    "    # Step 1: detect all boxes\n",
    "    for _ in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        results = model(frame, verbose=False)\n",
    "        detections = results[0].boxes.xyxy.cpu().numpy() if len(results[0].boxes) > 0 else []\n",
    "        if len(detections) > 0:\n",
    "            # take biggest box (person)\n",
    "            areas = (detections[:,2]-detections[:,0])*(detections[:,3]-detections[:,1])\n",
    "            box = detections[np.argmax(areas)]\n",
    "            boxes.append(box)\n",
    "        else:\n",
    "            boxes.append(None)\n",
    "    cap.release()\n",
    "\n",
    "    # Step 2: find valid range (first and last frame where a person exists)\n",
    "    valid_indices = [i for i,b in enumerate(boxes) if b is not None]\n",
    "    if not valid_indices:\n",
    "        print(f\"No detections found in {input_path}\")\n",
    "        return\n",
    "    \n",
    "    first_valid, last_valid = valid_indices[0], valid_indices[-1]\n",
    "\n",
    "    # Step 3: fill missing boxes in the middle only\n",
    "    for i in range(first_valid+1, last_valid):\n",
    "        if boxes[i] is None:\n",
    "            # interpolate between previous and next available boxes\n",
    "            prev_idx = max(j for j in range(i-1, first_valid-1, -1) if boxes[j] is not None)\n",
    "            next_idx = min(j for j in range(i+1, last_valid+1) if boxes[j] is not None)\n",
    "            if prev_idx is not None and next_idx is not None:\n",
    "                boxes[i] = (boxes[prev_idx] + boxes[next_idx]) / 2\n",
    "\n",
    "    # Step 4: crop & write\n",
    "    for i, frame in enumerate(frames):\n",
    "        if i < first_valid or i > last_valid:\n",
    "            crop = np.zeros((*output_size, 3), dtype=np.uint8)  # black frame\n",
    "        else:\n",
    "            box = boxes[i]\n",
    "            if box is not None:\n",
    "                x1, y1, x2, y2 = box\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "\n",
    "                # expand box\n",
    "                x1 = max(0, int(x1 - expand_ratio * w))\n",
    "                y1 = max(0, int(y1 - expand_ratio * h))\n",
    "                x2 = min(frame_width, int(x2 + expand_ratio * w))\n",
    "                y2 = min(frame_height, int(y2 + expand_ratio * h))\n",
    "\n",
    "                crop = frame[y1:y2, x1:x2]\n",
    "                crop = cv2.resize(crop, output_size)\n",
    "            else:\n",
    "                crop = np.zeros((*output_size, 3), dtype=np.uint8)\n",
    "        out.write(crop)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Saved cropped video to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76138b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped video to cropped_person110_1.mp4\n"
     ]
    }
   ],
   "source": [
    "crop_person_from_video(\n",
    "    model = model,\n",
    "    input_path=\"shop_lifter_110.mp4\",\n",
    "    output_path=\"cropped_person110_1.mp4\",\n",
    "    output_size=(256, 256),\n",
    "    expand_ratio = 0.3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Load model (already downloaded)\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# üìÇ Input and output directories\n",
    "input_root = \"Shop DataSet\"\n",
    "output_root = \"Processed_Dataset\"\n",
    "\n",
    "# ‚úÖ Ensure output directory exists\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(input_root):\n",
    "    class_input_dir = os.path.join(input_root, class_name)\n",
    "    class_output_dir = os.path.join(output_root, class_name)\n",
    "    os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nüîπ Processing class: {class_name}\")\n",
    "\n",
    "    # Loop through all videos in the class folder\n",
    "    for file in os.listdir(class_input_dir):\n",
    "        if not file.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(class_input_dir, file)\n",
    "        output_path = os.path.join(class_output_dir, file)\n",
    "\n",
    "        try:\n",
    "            print(f\"üé¨ Cropping: {file}\")\n",
    "            crop_person_from_video(model, input_path, output_path, target_size=(256, 256), num_frames=16)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to process {file}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ All videos processed and saved in 'Processed_Dataset/'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
